MODEL:
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  META_ARCHITECTURE: "CLIP_CISS"
  PRETRAINED: 'pretrained/ViT-B-16.pt'
  PRETRAINED_TEXT: 'pretrained/ViT-B-16.pt'
  WEIGHTS: ' '
  CONTEXT_LENGTH: 77
  # BACKBONE: 
  #   NAME: "VPTCLIPVisionTransformer"
  #   PATCH_SIZE: 16
  #   WIDTH: 768
  #   OUTPUT_DIM: 512
  #   GET_EMBEDDINGS: True
  #   DROP_PATH_RATE: 0.1
  #   LAYERS: 12
  #   INPUT_RESOLUTION: 512
  #   OUT_INDICES: [5,7,11]
  #   NUM_TOKENS: 10
  #   PROMPT_DIM: 768
  #   TOTAL_D_LAYER: 11
  BACKBONE: 
    NAME: "CLIPVisionTransformer"
    PATCH_SIZE: 16
    WIDTH: 768
    OUTPUT_DIM: 512
    GET_EMBEDDINGS: True
    DROP_PATH_RATE: 0.1
    LAYERS: 12
    INPUT_RESOLUTION: 512
    OUT_INDICES: [5,7,11]  #or [5,7,11]
    
    

  TEXT_ENCODER:
    NAME: 'CLIPTextEncoder'
    CONTEXT_LENGTH: 77
    EMBED_DIM: 512
    TRANSFORMER_WIDTH: 512
    TRANSFORMER_HEADS: 8
    TRANSFORMER_LAYERS: 12
    
  SEM_SEG_HEAD:
    NAME: 'ATMSingleHeadSeg'
    IMG_SIZE: 512
    IN_CHANNELS: 768 #512
    CHANNELS: 768 #512
    NUM_LAYERS: 3 #3
    NUM_CLASSES: 20
    NUM_HEADS: 8
    USE_PROJ: True #False
    USE_STAGES: 3
    EMBED_DIMS: 512
    
    MASK_WEIGHT: 50.0 #20.0 #100.0
    DICE_WEIGHT: 1.0
    LOSS_WEIGHT: 5.0 #1.0
    DEC_LAYERS: 3

  EXCLUDE_KEY: 'prompt'
  LOAD_TEXT_EMBEDDING: 'configs/voc/voc_single.npy'



DATASETS:
  TRAIN: ("voc_segm_train",)
  TEST: ("voc_segm_val",)
SOLVER:
  CHECKPOINT_PERIOD: 4000
  IMS_PER_BATCH: 2

  OPTIMIZER: "ADAMW"
  BASE_LR: 0.00002 #0.00002
  WEIGHT_DECAY: 0.01
  BACKBONE_MULTIPLIER: 1.0 #1.0
  HEAD_MULTIPLIER: 10.0   #??
  
  MAX_ITER: 25000 #60000 #80000

  LR_SCHEDULER_NAME: "WarmupPolyLR"
  WARMUP_FACTOR: 1e-6
  WARMUP_ITERS: 1500
  
  
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 35.0
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True

INPUT:
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 512) for x in range(5, 21)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 512
  MAX_SIZE_TRAIN: 2048
  MAX_SIZE_TEST: 2048
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (512, 512)
    SINGLE_CATEGORY_MAX_AREA: 1.0
  COLOR_AUG_SSD: True
  SIZE_DIVISIBILITY: 512  # used in dataset mapper
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"

TEST:
  # MASK_BG: False
  EVAL_PERIOD: 1000 #2000
  AUG:
    ENABLED: False
    MIN_SIZES: [256, 384, 512, 640, 768, 896]
    MAX_SIZE: 3584
    FLIP: True
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2
VERSION: 2
CONT:
  ORDER: !!python/object/apply:eval ["[x for x in range(1, 21)]"]
